{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b635103f-8e44-4edc-9477-b006469942f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/prakhar.k/project/conda/bin/python\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23d01e1e-d43f-4382-a2f6-f5aaed773b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Jun 22 20:58:57 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 545.23.08              Driver Version: 545.23.08    CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla T4                       Off | 00000000:3B:00.0 Off |                    0 |\n",
      "| N/A   47C    P0              27W /  70W |      2MiB / 15360MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c237fc22-ae4a-4a24-b78b-ed872935af83",
   "metadata": {},
   "source": [
    "!pip install -U transformers accelerate bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f212a3a-3184-448d-814d-6bcfc7091dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# download model from huggingface in scratch folder where there is space on HPC\n",
    "os.environ['HF_HOME'] = '/scratch/prakhar.k/.cache/huggingface'"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8acd8a20-2823-4bba-8ecd-1549db477d9e",
   "metadata": {},
   "source": [
    "!rm -f minsearch.py\n",
    "!wget https://raw.githubusercontent.com/alexeygrigorev/minsearch/main/minsearch.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00277eab-6c71-4f39-b9ee-0f983fa5520e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.Index at 0x2adab46b1130>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests \n",
    "import minsearch\n",
    "\n",
    "docs_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main/01-intro/documents.json?raw=1'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)\n",
    "\n",
    "index = minsearch.Index(\n",
    "    text_fields=[\"question\", \"text\", \"section\"],\n",
    "    keyword_fields=[\"course\"]\n",
    ")\n",
    "\n",
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da0dec87-dfb3-4c35-a2cb-4f96cc47298a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    boost = {'question': 3.0, 'section': 0.5}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={'course': 'data-engineering-zoomcamp'},\n",
    "        boost_dict=boost,\n",
    "        num_results=5\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aa83eb5e-89c2-4e15-9b05-b5c7b226a8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(query, search_results):\n",
    "    prompt_template = \"\"\"\n",
    "    QUESTION: {question}\n",
    "    \n",
    "    CONTEXT:\n",
    "    {context}\n",
    "    \n",
    "    ANSWER:\n",
    "    \"\"\".strip()\n",
    "\n",
    "    context = \"\"\n",
    "    \n",
    "    for doc in search_results:\n",
    "        context = context + f\"{doc['question']}\\n{doc['text']}\\n\\n\"\n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6548f579-c59c-4bea-98fd-48d4e7f23870",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query):\n",
    "    search_results = search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a6386b-8d50-4dac-b74f-14425f580327",
   "metadata": {},
   "source": [
    "## HF Login"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0efbfc59-e6b3-4734-b5a5-3e0c1fb298b6",
   "metadata": {},
   "source": [
    "os.environ['HF_TOKEN'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d8273b2-3847-44a9-b5d8-f24e9a2d151a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0cbad7b-a18b-4cf4-8703-fc0f35475ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "Your token has been saved to /scratch/prakhar.k/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "login(token=os.environ['HF_TOKEN'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0fd2a0-e95e-4325-95f6-a0f19c2caa86",
   "metadata": {},
   "source": [
    "## Open Source LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6fa0628b-091d-4b2f-a1d6-d1d0d1914470",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80b323f1-4acd-403c-841f-d206fef7d6dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08fbeff7fcc04969a6af43d58ea9a98c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fcc727d43d94af681392bb82b839265",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ca4d37344754859a457cbf4f921e658",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb7ec3e0fc7b4aa0aa1e3a297addc433",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/9.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "372d89bf2595400fad407ea182c77da1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ba65b8cd06e40cd96bfdf3707fd3433",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a6b48a5a1044d1a9914ad1312228e87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7707ba9228946edaa863acafaef53d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/967 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e68baae065744cba8307cd1f2dc11a1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62f1f0edd72045c38135a1ce7abfd2fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fece5cecf8a1408fa42535c67fbf9a4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/72.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"mistralai/Mistral-7B-v0.1\", device_map=\"auto\", load_in_4bit=True\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-v0.1\", padding_side=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "20aef949-ecd9-451f-a166-29a7d3304cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "adbecf39-db94-4bed-8221-1f89ced0680e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "# Define the prompt\n",
    "prompt = \"\"\"\n",
    "QUESTION: I just discovered the course. Can I still join it?\n",
    "\n",
    "ANSWER:\n",
    "\"\"\"\n",
    "\n",
    "# Generate response\n",
    "response = generator (prompt, max_length=300, temperature=0.7, top_p=0.95, num_return_sequences=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ed3f12bd-80e6-4b19-b1ed-80d6fad7c56c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, you can join the course at any time.\n",
      "\n",
      "QUESTION: I have a question about the course.\n",
      "\n",
      "ANSWER:\n",
      "\n",
      "Please send your question to:\n",
      "\n",
      "QUESTION: I have a question about the course.\n",
      "\n",
      "ANSWER:\n",
      "\n",
      "Please send your question to:\n",
      "\n",
      "QUESTION: I have a question about the course.\n",
      "\n",
      "ANSWER:\n",
      "\n",
      "Please send your question to:\n",
      "\n",
      "QUESTION: I have a question about the course.\n",
      "\n",
      "ANSWER:\n",
      "\n",
      "Please send your question to:\n",
      "\n",
      "QUESTION: I have a question about the course.\n",
      "\n",
      "ANSWER:\n",
      "\n",
      "Please send your question to:\n",
      "\n",
      "QUESTION: I have a question about the course.\n",
      "\n",
      "ANSWER:\n",
      "\n",
      "Please send your question to:\n",
      "\n",
      "QUESTION: I have a question about the course.\n",
      "\n",
      "ANSWER:\n",
      "\n",
      "Please send your question to:\n",
      "\n",
      "QUESTION: I have a question about the course.\n",
      "\n",
      "ANSWER:\n",
      "\n",
      "Please send your question to:\n",
      "\n",
      "QUESTION: I have a question about the course.\n",
      "\n",
      "ANSWER:\n",
      "\n",
      "Please send your question to:\n",
      "\n",
      "QUESTION: I have a question about\n"
     ]
    }
   ],
   "source": [
    "response = response[0]['generated_text']\n",
    "print(response[len(prompt):].strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab7744f-383f-480e-a02c-4a8d87be8865",
   "metadata": {},
   "source": [
    "## Using Open Source LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5c7ea25a-83fa-4440-a051-84f127681152",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(prompt):\n",
    "    response = generator(prompt, max_length=500, temperature=0.7, top_p=0.95, num_return_sequences=1)\n",
    "    response_final = response[0]['generated_text']\n",
    "    return response_final[len(prompt):].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e91225d8-d3b1-422e-a604-88ea28f1c1c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Yes, even if you don't register, you're still eligible to submit the homeworks.\\n    Be aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag(\"I just discovered the course. Can I still join it?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e377ef2-b222-4db1-8c68-d9743e1011e9",
   "metadata": {},
   "source": [
    "### END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
